import streamlit as st
import PyPDF2
import docx
from textblob import TextBlob
from collections import Counter
import re
from transformers import pipeline
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from io import BytesIO
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib import colors
from reportlab.lib.units import inch
from reportlab.lib.enums import TA_CENTER
from reportlab.lib.styles import ParagraphStyle
import subprocess



import spacy
import streamlit as st

@st.cache_resource
def load_spacy_model():
    return spacy.load("en_core_web_sm")

nlp = load_spacy_model()






# Load Hugging Face summarization model
@st.cache_resource
def load_summarizer():
    return pipeline("summarization", model="facebook/bart-large-cnn")

summarizer = load_summarizer()

# -----------------------------
# Helper functions
# -----------------------------
def extract_text_from_pdf(uploaded_file):
    text = ""
    reader = PyPDF2.PdfReader(uploaded_file)
    for page in reader.pages:
        text += page.extract_text() + "\n"
    return text

def extract_text_from_docx(uploaded_file):
    doc = docx.Document(uploaded_file)
    return "\n".join([p.text for p in doc.paragraphs])

def clean_text(text):
    return re.sub(r'\s+', ' ', text.strip())

def analyze_text(text):
    blob = TextBlob(text)
    doc = nlp(text)

    # Sentiment
    sentiment = blob.sentiment.polarity

    # Keywords
    words = [word.lower() for word in re.findall(r'\b\w+\b', text)]
    common_words = Counter(words).most_common(10)

    # Named Entities
    entities = [(ent.text, ent.label_) for ent in doc.ents]

    return sentiment, common_words, entities, words

def ai_summary(text):
    max_chunk = 1000
    text_chunks = [text[i:i+max_chunk] for i in range(0, len(text), max_chunk)]
    summary = ""
    for chunk in text_chunks:
        result = summarizer(chunk, max_length=150, min_length=30, do_sample=False)
        summary += result[0]['summary_text'] + " "
    return summary.strip()

def generate_wordcloud(words):
    text = " ".join(words)
    wordcloud = WordCloud(width=800, height=400, background_color="white").generate(text)
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation="bilinear")
    ax.axis("off")
    buf = BytesIO()
    plt.savefig(buf, format="png")
    st.pyplot(fig)
    buf.seek(0)
    return buf



def create_pdf(summary, sentiment, keywords, entities, wordcloud_buf):
    buffer = BytesIO()
    doc = SimpleDocTemplate(
        buffer,
        pagesize=letter,
        rightMargin=50,
        leftMargin=50,
        topMargin=50,
        bottomMargin=50
    )

    styles = getSampleStyleSheet()

    # Custom styles
    title_style = ParagraphStyle(
        name="TitleStyle",
        parent=styles["Title"],
        fontSize=22,
        textColor=colors.HexColor("#004AAD"),
        alignment=TA_CENTER,
        spaceAfter=20
    )

    section_header = ParagraphStyle(
        name="SectionHeader",
        parent=styles["Heading2"],
        fontSize=14,
        textColor=colors.HexColor("#004AAD"),
        spaceBefore=10,
        spaceAfter=8,
        underlineWidth=1,
        underlineColor=colors.HexColor("#004AAD")
    )

    normal_text = ParagraphStyle(
        name="NormalText",
        parent=styles["Normal"],
        fontSize=11,
        leading=15
    )

    story = []

    # Header Section
    story.append(Paragraph("üß† AI Document Analyzer Report", title_style))
    story.append(Paragraph("Generated by Priyanka‚Äôs AI Analyzer", normal_text))
    story.append(Spacer(1, 15))
    story.append(Paragraph("<hr/>", normal_text))
    story.append(Spacer(1, 10))

    # Summary Section
    story.append(Paragraph("üìë Summary", section_header))
    story.append(Paragraph(summary, normal_text))
    story.append(Spacer(1, 12))

    # Sentiment Section
    story.append(Paragraph("üòä Sentiment Analysis", section_header))
    story.append(Paragraph(f"<b>Polarity Score:</b> {sentiment:.2f}", normal_text))
    if sentiment > 0:
        story.append(Paragraph("Overall Sentiment: <font color='green'><b>Positive</b></font>", normal_text))
    elif sentiment < 0:
        story.append(Paragraph("Overall Sentiment: <font color='red'><b>Negative</b></font>", normal_text))
    else:
        story.append(Paragraph("Overall Sentiment: <font color='gray'><b>Neutral</b></font>", normal_text))
    story.append(Spacer(1, 12))

    # Keywords Section
    story.append(Paragraph("üîë Top Keywords", section_header))
    if keywords:
        keyword_text = "<br/>".join([f"{w}: {f}" for w, f in keywords])
        story.append(Paragraph(keyword_text, normal_text))
    else:
        story.append(Paragraph("No significant keywords found.", normal_text))
    story.append(Spacer(1, 12))

    # Entities Section
    story.append(Paragraph("üè∑Ô∏è Named Entities", section_header))
    if entities:
        entity_text = "<br/>".join([f"{ent} ({label})" for ent, label in entities])
        story.append(Paragraph(entity_text, normal_text))
    else:
        story.append(Paragraph("No named entities found.", normal_text))
    story.append(Spacer(1, 12))

    # Word Cloud Section
    if wordcloud_buf:
        story.append(Paragraph("‚òÅÔ∏è Word Cloud", section_header))
        img = Image(wordcloud_buf, width=5.5*inch, height=3*inch)
        story.append(img)
        story.append(Spacer(1, 12))

    # Footer
    story.append(Spacer(1, 20))
    story.append(Paragraph(
        "<hr/><br/><b>Report generated using AI Document Analyzer</b><br/>¬© 2025 Priyanka Gounder",
        ParagraphStyle(name="Footer", alignment=TA_CENTER, fontSize=9, textColor=colors.gray)
    ))

    doc.build(story)
    buffer.seek(0)
    return buffer


# -----------------------------
# Streamlit UI
# -----------------------------
st.set_page_config(page_title="AI Document Analyzer", page_icon="üß†", layout="wide")

st.title("üß† AI Document Analyzer")
st.markdown("Upload a document (PDF, DOCX, or TXT) and get **AI-powered insights** ‚Äî including summary, sentiment, keywords, named entities, a word cloud, and downloadable PDF report!")

uploaded_file = st.file_uploader("üìÅ Upload your document", type=["pdf", "docx", "txt"])

if uploaded_file:
    file_type = uploaded_file.name.split('.')[-1].lower()
    
    if file_type == "pdf":
        text = extract_text_from_pdf(uploaded_file)
    elif file_type == "docx":
        text = extract_text_from_docx(uploaded_file)
    elif file_type == "txt":
        text = uploaded_file.read().decode("utf-8")
    else:
        st.error("Unsupported file type!")
        st.stop()
    
    text = clean_text(text)
    
    if len(text) < 50:
        st.warning("The document seems too short for analysis.")
    else:
        st.subheader("üìÑ Extracted Text (Preview)")
        st.text_area("Text Preview", text[:1000] + "..." if len(text) > 1000 else text, height=200)

        with st.spinner("üß† Generating AI Summary..."):
            summary = ai_summary(text)
        
        sentiment, keywords, entities, all_words = analyze_text(text)

        st.subheader("üîç Analysis Results")

        st.markdown("### üìë AI Summary")
        st.write(summary)

        st.markdown("### üòä Sentiment Analysis")
        st.write(f"Polarity Score: `{sentiment:.2f}`")
        if sentiment > 0:
            st.success("Overall Sentiment: Positive")
        elif sentiment < 0:
            st.error("Overall Sentiment: Negative")
        else:
            st.info("Overall Sentiment: Neutral")

        st.markdown("### üîë Top Keywords")
        for word, freq in keywords:
            st.write(f"- {word}: {freq}")

        st.markdown("### üè∑Ô∏è Named Entities")
        if entities:
            for ent, label in entities:
                st.write(f"- {ent} ({label})")
        else:
            st.write("No named entities found.")

        st.markdown("### ‚òÅÔ∏è Word Cloud")
        wordcloud_buf = generate_wordcloud(all_words)

        # Generate and download PDF
        pdf_buffer = create_pdf(summary, sentiment, keywords, entities, wordcloud_buf)

        st.download_button(
            label="üì• Download Full Report as PDF",
            data=pdf_buffer,
            file_name="AI_Document_Analysis_Report.pdf",
            mime="application/pdf"
        )
